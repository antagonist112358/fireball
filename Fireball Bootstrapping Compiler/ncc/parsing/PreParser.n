/*
 * Copyright (c) 2003-2008 The University of Wroclaw.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *    1. Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *    2. Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *    3. The name of the University may not be used to endorse or promote
 *       products derived from this software without specific prior
 *       written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE UNIVERSITY ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
 * NO EVENT SHALL THE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

using Nemerle.Compiler;
using Nemerle.Collections;
using Nemerle.Compiler.Parsetree;
using Nemerle.Surround;
using Nemerle.Utility;
using SCG = System.Collections.Generic;
using System.Linq;

namespace Nemerle.Compiler
{
  class PreParserException : System.Exception
  {
    [Accessor]
    public mutable _location : Location;

    public this (location : Location, msg : string) {
      base (msg);
      _location = location;
    }
  }

  /** Transforms stream of tokens from given LexerBase to token tree
      with matched brackets.
   */
  public class PreParser
  {
    protected lexer : LexerBase;
    protected mutable token_buffer : Stack [Token] = Stack(2);
    private mutable last_declaration_token : Token = null;
    mutable Env : GlobalEnv;

    mutable finished : bool = false;

    /** Parent stream is the stack of processed token nodes,
        which are already assigned to be in currently build sequence.
        For example:
          a; b; c (); d e _we_are_here_
        'a, b, c()', are alredy known to be in parent sequence,
        while 'd e' are in current temporary sequence, which might
        get added to parent_stream if separator (e.g. ';') occurs
     */
    parent_stream : SCG.List [Token] = SCG.List (100);

    /** Currently builded stream of token nodes is an array of
        loose tokens, which have occured after last separator.
        It will probably form LooseGroup as an element of parent
        sequence or all elements will constitue parent
     */
    current_stream : SCG.List [Token] = SCG.List (50);

    [Nemerle.Utility.Accessor (flags = WantSetter | Internal)]
    mutable doc_comments : Map [Location, string];

    public this (lex : LexerBase) {
      this (lex, lex.Manager.CoreEnv);
    }

    public this (lex : LexerBase, env : GlobalEnv) {
      Env = env;
      lex.Keywords = Env.Keywords;
      lexer = lex;
    }

    reset_comment (tok : Token) : void {
      when (doc_comments != null) doc_comments = doc_comments.Replace (tok.Location, "");
    }
    reset_comment (loc : Location) : void {
      when (doc_comments != null) doc_comments = doc_comments.Replace (loc, "");
    }

    // Gets the next token (optionally skipping newline tokens)
    protected virtual get_token(skip_newlines: bool = false) : Token {
      mutable tok = read_token();
      while (skip_newlines && tok is Token.NewLine) {
        tok = read_token();
      }
      tok
    }
    
    // Reads the next token from either the token_buffer or the lexer stream
    private read_token() : Token
    {
      if (!token_buffer.IsEmpty)
      {
        def result = token_buffer.Pop();
        result;
      }
      else
      {
        try        
        {
          match (lexer.GetToken ())
          {
            | QuotedIdentifier (x) as q => Token.Identifier (q.Location, x)
            | t => t
          }
        }
        catch
        {
          | _ is System.Text.DecoderFallbackException =>
            Message.FatalError (lexer.Location, $"detected unsupported encoding of national characters in file `$(lexer.Location.File)', "
              "source files should be in UTF8 (or UTF16/32 when BOM is given) encoding");
          | e is LexerBase.Error =>
            Message.Error (lexer.Location, e.Message + " " + e.StackTrace);
            read_token()
        }
      }
    }

    /** Store token in our mini one token buffer */
    push_back(tok : Token) : void
    {
        token_buffer.Push(tok);
    }

    // Peek ahead one token in the token stream
    peek_token() : Token
    {
      def tok = get_token();
      push_back(tok);
      tok
    }
    
    // Reads and consumes the next token if it is a newline
    swallow_newlines() : void {
      while(peek_token() is Token.NewLine)
      {
        _ = get_token()
      }
    }
    
    // Checks to see if a newline can be interpreted as a semicolon / statement terminator
    private terminates_statement(_: Token.NewLine) : bool {
      // Read through any additional newline characters
      swallow_newlines();
      
      // Get the last token seen
      def prevOption = current_stream.LastOrDefault().ToOption();
      
      // Get the next token
      def next = peek_token();
      
      // Can the last token terminate a statement?
      def prev_terminates() : bool {
        match(prevOption)  {
          | None => false
          | Some(prev) => match(prev) {
            | Token.CharLiteral | Token.DecimalLiteral | Token.DoubleLiteral | Token.FloatLiteral | Token.IntegerLiteral | Token.StringLiteral
            | Token.Identifier | Token.QuotedIdentifier 
            | Token.BracesGroup | Token.QuoteGroup | Token.RoundGroup | Token.SquareGroup => true
            | Token.Import => true
            | Token.Keyword(kw) when Keywords.TerminalKeywords.Contains(kw) => true
            | _ => false
          }
        }
      }
      
      // Can the next token start a new statement?
      def next_starts_new() : bool {
        match(next) {
          // Skip all the begin group tokens, since they will start new groups
          | Token.BeginSquare | Token.BeginBrace | Token.BeginQuote | Token.BeginRound
          // Skip all the end group tokens, since they end a group
          | Token.EndBrace | Token.EndQuote | Token.EndRound | Token.EndSquare
          // Operators never start a new statement
          | Token.Operator => false
          | Token.Keyword(kw) when Keywords.KeywordsWhichNeverStartNewStatement.Contains(kw) => false
          | _ => true
        }
      }
      
      // Check
      prev_terminates() && next_starts_new()
    }
    
    /** links Tokens from specified subarray to form a list and return its head */
    static make_list (tokens : SCG.List [Token], start : int) : Token
    {
      for (mutable i = tokens.Count - 2; i >= start; --i)
        tokens [i].Next = tokens [i + 1];
      tokens [start]
    }

    /** returns a combined location of the subarray inside a token list */
    static list_location ( tokens : SCG.List [Token], start : int) : Location
    {
      assert(tokens.Count > 0);
      assert(start < tokens.Count);
      tokens [start].Location + tokens [tokens.Count - 1].Location
    }

    public static Dump (tok : Token, ident : string) : string
    {
      def (open, close, sepstr, elements) =
        match (tok) {
          | Token.RoundGroup => ("(", ")", ", ", tok)
          | Token.BracesGroup => ("{\n" + ident, "}", ";\n" + ident, tok)
          | Token.SquareGroup => ("[", "]", ", ", tok)
          | Token.QuoteGroup  => ("<[\n", "]>", "; ", tok)
          | Token.LooseGroup  => ("", "", " ", tok)

          | _ => ("", tok.ToString (false), "", null)
        }

      $"$open..$(elements; sepstr)$close"
    }
        
    /** Closes both currently created LooseGroup and parent group.
        Returns list of tokens composing parent group */
    finish_parent (parent_begin : int, current_begin : int) : Token {
      finish_current (current_begin);
      def parent_group =
        if (parent_begin == parent_stream.Count)
          null // case of `(` `)`
        else
          make_list (parent_stream, parent_begin);
      parent_stream.RemoveRange (parent_begin, parent_stream.Count - parent_begin);
      parent_group
    }


    /** Closes currently created LooseGroup and adds it at the end of the
        parent group. After that we are ready to make another LooseGroup.

        It is called mainly when separator token occurs.
     */
    finish_current (current_begin : int, separator_token : Token = null) : void
    {
      if (current_begin == current_stream.Count)
        when (separator_token != null && !(separator_token is Token.Semicolon) && !(separator_token is Token.NewLine))
        {
          def loose = Token.LooseGroup (separator_token.Location, separator_token);
          parent_stream.Add (loose);
        }
      else
      {
        def loose_group = make_list (current_stream, current_begin);
        def location    = if (separator_token != null)
                            loose_group.Location + separator_token.Location.FromStart();
                          else
                            list_location (current_stream, current_begin);
        def loose       = Token.LooseGroup(location, loose_group, separator_token);

        parent_stream.Add (loose);
        current_stream.RemoveRange (current_begin, current_stream.Count - current_begin);
      }
    }            
    
    /** Handle standard situations when new bracket group is beginning
        or there is erronous situation. Any non bracket token is
        appended to current LooseGroup.

        Throws PreParserException when there is unmatched end bracket.
     */
    handle_default_token (current_begin : int, tok : Token, braces_cut_current = true, newlines_enabled = true) : void
    {
      match (tok)
      {
        | Token.BeginBrace(generated) as openBrace =>
          // Eat any trailing newlines
          swallow_newlines();
          def brace_group = parse_brace_group(tok.Location, openBrace, true, generated);
          //Message.Debug($"Writing: $(get_token_type(brace_group))");
          current_stream.Add(brace_group);

          when (braces_cut_current) {
            def next_token = peek_token();
            if (next_token is Token.Semicolon)
              finish_current(current_begin, get_token());
            else
              finish_current(current_begin);            
          }
        | Token.BeginRound as openBrace =>
          def round_group = parse_round_group(tok.Location, openBrace);
          //Message.Debug($"Writing: $(get_token_type(round_group))");
          current_stream.Add(round_group);

        | Token.BeginSquare as openBrace =>
          def square_group = parse_square_group(tok.Location, openBrace);
          //Message.Debug($"Writing: $(get_token_type(square_group))");
          current_stream.Add(square_group);

        | Token.BeginQuote as openBrace =>
          // Eat any trailing newlines
          swallow_newlines();
          def quote_group = parse_quote_group(tok.Location, openBrace);
          //Message.Debug($"Writing: $(get_token_type(quote_group))");
          current_stream.Add(quote_group);

        | Token.EndRound | Token.EndSquare | Token.EndQuote | Token.EndBrace =>
          push_back (tok);
          throw PreParserException (tok.Location, $"unexpected closing bracket `$(tok)'");

        | Token.EndOfFile =>
          throw PreParserException (tok.Location, "unexpected end of file");

        | Token.Comment (comment) when doc_comments != null =>
          doc_comments = doc_comments.Replace (tok.Location, comment);

        | Token.Comment => ()
        | Token.NewLine as nl =>
          when (newlines_enabled && terminates_statement(nl)) {
            finish_current(current_begin, tok);
          }
        | _ => current_stream.Add (tok);
      }
    }

    parse_brace_group (loc : Location, openBrace : Token.BeginBrace, expect_endbrace : bool, generated : bool) : Token.BracesGroup
    {
      def parent_begin = parent_stream.Count;
      def current_begin = current_stream.Count;
      Env = Env.CreateScope();
      
      reset_comment (loc);
      
      def loop ()
      {
        def tok = get_token ();
        unless(ReferenceEquals(Env.Defines, lexer.Defines))
          Env = Env.SetDefines(lexer.Defines);
        match (tok)
        {          
          // finish entire brace group
          | Token.EndBrace as closeBrace =>
            reset_comment(tok);
            def brace_group = finish_parent(parent_begin, current_begin);
            Token.BracesGroup(loc + tok.Location, brace_group, openBrace, closeBrace, generated);

          // finish current loose group
          | Token.Semicolon =>
            reset_comment(tok);
            finish_current(current_begin, tok);
            loop()

          // Import statement
          | Token.Keyword("using") =>
            parse_nested_using(current_begin, tok);
            loop()
          
          | Token.EndOfFile when !expect_endbrace =>
            def brace_group = finish_parent (parent_begin, current_begin);
            finished = true;
            Token.BracesGroup (loc + tok.Location, brace_group, openBrace, null, generated);
            
          | _ => handle_default_token (current_begin, tok); loop ()
        }
      }
      try { loop () }
      catch { e is PreParserException =>
        Message.Error (loc, "when parsing this `{' brace group");
        Message.Error (e.Location, e.Message);
        def group = finish_parent (parent_begin, current_begin);
        Token.BracesGroup (shift_end(loc + e.Location), group, openBrace, null, generated);
      } finally {
        Env = Env.Close();
      }
    }

    parse_round_group(loc : Location, openBrace : Token.BeginRound) : Token.RoundGroup
    {
      def parent_begin = parent_stream.Count;
      def current_begin = current_stream.Count;

      def loop () {
        def tok = get_token (true);
        match (tok) {
          // finish entire round group
          | Token.EndRound as closeBrace =>
            def round_group = finish_parent (parent_begin, current_begin);          
            Token.RoundGroup (loc + tok.Location, round_group, openBrace, closeBrace);
          // finish current loose group
          | Token.Comma =>
            finish_current (current_begin, tok);
            loop ()
          // Otherwise...
          | _ => handle_default_token (current_begin, tok, false, false); loop ()
        }
      }
      try { loop () }
      catch
      { e is PreParserException =>
        def Manager = lexer.Manager; // need for surroundwith (related_messages)
        surroundwith (related_messages)
        {
          Message.Error (loc, "unclosed bracket");
          Message.Hint (e.Location, $"$(e.Message) when parsing this `(' brace group");
        }
        def group = finish_parent (parent_begin, current_begin);
        Token.RoundGroup (shift_end(loc + e.Location), group, openBrace, null);
      }
    }

    parse_square_group (loc : Location, openBrace : Token.BeginSquare) : Token.SquareGroup
    {
      def parent_begin = parent_stream.Count;
      def current_begin = current_stream.Count;

      def loop () {
        def tok = get_token (true);
        match (tok) {
          // finish entire brace group
          | Token.EndSquare as closeBrace =>
            def group = finish_parent (parent_begin, current_begin);
            def groupLoc = loc + tok.Location;
            when (group != null)
              group.Location = groupLoc;
            Token.SquareGroup (groupLoc, group, openBrace, closeBrace);

          // finish current loose group
          | Token.Comma => finish_current (current_begin, tok); loop ()
          
          // Otherwise...
          | _ => handle_default_token (current_begin, tok, false, false); loop ()
        }
      }
      try { loop () }
      catch { e is PreParserException =>
        Message.Error (loc, "when parsing this `[' brace group");
        Message.Error (e.Location, e.Message);
        def group = finish_parent (parent_begin, current_begin);
        def groupLoc = loc + e.Location;
        when (group != null)
          group.Location = groupLoc;
        Token.SquareGroup (shift_end(groupLoc), group, openBrace, null);
      }
    }

    // Todo: Fix me like brace group!
    parse_quote_group (loc : Location, openBrace : Token.BeginQuote) : Token.QuoteGroup
    {
      def parent_begin = parent_stream.Count;
      def current_begin = current_stream.Count;

      def loop () {
        def tok = get_token ();
        match (tok) {
          // finish entire brace group
          | Token.EndQuote as closeBrace =>
            def group = finish_parent (parent_begin, current_begin);
            Token.QuoteGroup (loc + tok.Location, group, openBrace, closeBrace);

          // finish current loose group
          | Token.Semicolon => finish_current (current_begin, tok); loop ()
          | _ => handle_default_token (current_begin, tok); loop ()
        }
      }
      try { loop () }
      catch { e is PreParserException =>
        Message.Error (loc, "when parsing this `<[' brace group");
        Message.Error (e.Location, e.Message);
        def group = finish_parent (parent_begin, current_begin);
        Token.QuoteGroup (shift_end(loc + e.Location), group, openBrace, null);
      }
    }

    get_qualified_tokens (read_through_newlines : bool = false) : list [string] * list [Location] * list[Token]
    {
      def tok1 = get_token (read_through_newlines);
      match (tok1)
      {
          | Token.Identifier (x) =>
          def tok2 = get_token();
          match (tok2)
          {
              | Token.Operator (".") =>
              def (ident, locs, toks) = get_qualified_tokens (true);
              match (ident)
              {
                  | [] => ([x], [tok1.Location, tok2.Location], [tok1, tok2])
                  | _  => (x :: ident, tok1.Location :: tok2.Location :: locs, tok1 :: tok2 :: toks)
              }
              | t => push_back (t); ([x], [tok1.Location], [tok1])
          }
          | t =>
          Message.Error (t.Location, $"expected qualified identifier, got token $t");
          push_back (t);
          ([], [], [])
      }
    }
    
    parse_nested_using(current_begin: int, tok: Token) : void {
      
      def make_before_location (location)
      {
        Location(location.FileIndex, location.Line, location.Column);
      }      
      
      
      // Check if this is a 'using (resource) { ... }' block
      if(peek_token() is Token.BeginRound)
      {
        current_stream.Add(tok);
      } else {
        finish_current(current_begin);
      
        def (id, idLocs, idToks) = get_qualified_tokens ();
      
        mutable currentNsEnv = Env; // GlobalEnv of current namespace        
        mutable tokens_in_body = idToks;        
        
        def create_body_token()
        {
          def body = tokens_in_body.Rev();
          mutable next = body.Tail;
          mutable loc = body.Head.Location;

          body.Iter(current =>
            {
              current.Next = match (next) { | [] => null | _ => next.Head };
              unless (next == []) next = next.Tail;
              loc += current.Location;
            });
          Token.LooseGroup(loc, body.Head);
        }               
      
        match (get_token ()) {
          | Token.NewLine as st | Token.Semicolon as st =>
              swallow_newlines();
              def loc = tok.Location;
              Env = Env.AddOpenNamespace (id, loc);
              lexer.Keywords = Env.Keywords;

              def using_tok = Token.Import (loc, Env, tok, create_body_token());
              current_stream.Add (using_tok);
              
              lexer.Manager.OnAfterUsingDirectiveParse(loc + make_before_location (st.Location), id, idLocs,
                "", Location.Default, currentNsEnv, Env);

          | Token.Operator ("=") as eq =>
              def (id2, idLocs2, idToks2) = get_qualified_tokens ();

              tokens_in_body = (eq :: tokens_in_body).Append(idToks2);

              def st = get_token ();
              def ty =
                match (st)
                {
                  | Token.Semicolon | Token.NewLine => swallow_newlines(); null
                  | Token.BeginSquare => parseTypeName(idToks2, st)
                  | _ =>
                    push_back (st);
                    Message.Error(st.Location, "expecting `;' after using alias");
                    null
                };

              match (id)
              {
                | [name] when ty == null =>
                  Env = Env.AddNamespaceAlias (name, id2, tok.Location);
                  lexer.Manager.OnAfterUsingDirectiveParse(tok.Location
                    + make_before_location (st.Location), id2, idLocs2,
                    name, idLocs.Head, currentNsEnv, Env);
                  assert(idLocs.Length == 1);

                | [_name] => ()
                  // make generic type alias...

                | [] => // occur if syntax error
                  lexer.Manager.OnAfterUsingDirectiveParse(tok.Location
                    + make_before_location (st.Location), id2, idLocs2,
                    "", Location.Default, currentNsEnv, Env);

                | _ =>
                  Message.Error (tok.Location, "using alias must be simple name without dots");
                  lexer.Manager.OnAfterUsingDirectiveParse(tok.Location
                    + make_before_location (st.Location), id2, idLocs2,
                    id.ToString(), idLocs.Head + idLocs.Last, currentNsEnv, Env);
              }

              def using_tok = Token.Import (tok.Location + st.Location, Env, tok, create_body_token());
              //Message.Debug($"Writing token: $(get_token_type(using_tok))");
              current_stream.Add (using_tok);              
              
          | x =>
            push_back (x);
            // The error message must point to last using token
            def loc1 = match (idLocs) { | [] => tok.Location | _ => idLocs.Last };
            def loc2 = Location(loc1.FileIndex, loc1.EndLine, loc1.EndColumn);
            Message.Error (loc2, "expecting `;' or `=' or EOL");
            // In notification location must point before first token of next directive
            lexer.Manager.OnAfterUsingDirectiveParse(tok.Location + x.Location.FromStart(),
              id, idLocs, "", Location.Default, currentNsEnv, Env);          
        }
        
      }      
      
    }
    
    ParseTopLevelImpl (nesting : int = 0) : Token
    {
      def parent_begin = parent_stream.Count;
      def current_begin = current_stream.Count;
      mutable currentNsEnv = Env; // GlobalEnv of current namespace
      
      def get_qualified_identifier () : list [string] * list [Location]
      {
        def tok1 = get_token ();
        match (tok1)
        {
          | Token.Identifier (x) =>
            def tok2 = get_token(); //skip_newlines(get_token());
            match (tok2)
            {
              | Token.Operator (".") =>
                def (ident, locs) = get_qualified_identifier ();
                match (ident)
                {
                  | [] => ([x], [tok1.Location, tok2.Location])
                  | _  => (x :: ident, tok1.Location :: tok2.Location :: locs)
                }
              | t => push_back (t); ([x], [tok1.Location])
            }
          | t =>
            Message.Error (t.Location, $"expected qualified identifier, got token $t");
            push_back (t);
            ([], [])
        }
      }

      def make_before_location (location)
      {
        Location(location.FileIndex, location.Line, location.Column);
      }

      def parse_using_directive (tok)
      {
        finish_current (current_begin);
        def (id, idLocs, idToks) = get_qualified_tokens ();

        mutable tokens_in_body = idToks;

        def create_body_token()
        {
          def body = tokens_in_body.Rev();
          mutable next = body.Tail;
          mutable loc = body.Head.Location;

          body.Iter(current =>
            {
              current.Next = match (next) { | [] => null | _ => next.Head };
              unless (next == []) next = next.Tail;
              loc += current.Location;
            });
          Token.LooseGroup(loc, body.Head);
        }

        match (get_token ()) {
          | Token.NewLine as st =>
            swallow_newlines();
            def loc = tok.Location;
            Env = Env.AddOpenNamespace (id, loc);
            lexer.Keywords = Env.Keywords;

            def using_tok = Token.Import (loc, Env, tok, create_body_token());
            //Message.Debug($"Writing token: $(get_token_type(using_tok))");
            current_stream.Add (using_tok);
            current_stream.Add (Token.Semicolon(st.Location, true));                
            
            lexer.Manager.OnAfterUsingDirectiveParse(loc
              + make_before_location (st.Location), id, idLocs,
              "", Location.Default, currentNsEnv, Env);

          | Token.Semicolon as st =>
            def loc = tok.Location + st.Location;
            Env = Env.AddOpenNamespace (id, loc);
            lexer.Keywords = Env.Keywords;

            def using_tok = Token.Import (loc, Env, tok, create_body_token());
            current_stream.Add (using_tok);

            //Message.Debug($"Writing token: $(get_token_type(using_tok))");
            
            lexer.Manager.OnAfterUsingDirectiveParse(loc
              + make_before_location (st.Location), id, idLocs,
              "", Location.Default, currentNsEnv, Env);

          | Token.Operator ("=") as eq =>
            def (id2, idLocs2, idToks2) = get_qualified_tokens ();

            tokens_in_body = (eq :: tokens_in_body).Append(idToks2);

            def st = get_token ();
            def ty =
              match (st)
              {
                | Token.Semicolon => null
                | Token.NewLine => swallow_newlines(); null
                | Token.BeginSquare => parseTypeName(idToks2, st)
                | _ =>
                  push_back (st);
                  Message.Error(st.Location, "expecting `;' or EOL after using alias");
                  null
              };

            match (id)
            {
              | [name] when ty == null =>
                Env = Env.AddNamespaceAlias (name, id2, tok.Location);
                lexer.Manager.OnAfterUsingDirectiveParse(tok.Location
                  + make_before_location (st.Location), id2, idLocs2,
                  name, idLocs.Head, currentNsEnv, Env);
                assert(idLocs.Length == 1);

              | [_name] => ()
                // make generic type alias...

              | [] => // occur if syntax error
                lexer.Manager.OnAfterUsingDirectiveParse(tok.Location
                  + make_before_location (st.Location), id2, idLocs2,
                  "", Location.Default, currentNsEnv, Env);

              | _ =>
                Message.Error (tok.Location, "using alias must be simple name without dots");
                lexer.Manager.OnAfterUsingDirectiveParse(tok.Location
                  + make_before_location (st.Location), id2, idLocs2,
                  id.ToString(), idLocs.Head + idLocs.Last, currentNsEnv, Env);
            }

            def using_tok = Token.Import (tok.Location + st.Location, Env, tok, create_body_token());
            //Message.Debug($"Writing token: $(get_token_type(using_tok))");
            current_stream.Add (using_tok);

          | x =>
            push_back (x);
            // The error message must point to last using token
            def loc1 = match (idLocs) { | [] => tok.Location | _ => idLocs.Last };
            def loc2 = Location(loc1.FileIndex, loc1.EndLine, loc1.EndColumn);
            Message.Error (loc2, "expecting `;' or `=' or EOL");
            // In notification location must point before first token of next directive
            lexer.Manager.OnAfterUsingDirectiveParse(tok.Location + x.Location.FromStart(),
              id, idLocs, "", Location.Default, currentNsEnv, Env);
        }

        finish_current (current_begin);
      }

      def loop ()
      {       
        def tok = get_token ();
        unless(ReferenceEquals(Env.Defines, lexer.Defines))
          Env = Env.SetDefines(lexer.Defines);
        match (tok)
        {
          | Token.Keyword ("using") => parse_using_directive (tok); loop ()

          | Token.Keyword ("namespace") =>
            finish_current (current_begin);

            def prevNsEnv = currentNsEnv;
            currentNsEnv = Env;

            def (id, idLocs) = get_qualified_identifier ();
            def headerLocation = if (idLocs.IsEmpty) tok.Location else tok.Location + idLocs.Last;

            match (get_token (true))
            {
              | Token.BeginBrace as br =>
                last_declaration_token = null;
                def loc = tok.Location + br.Location;
                def oldEnv = Env;
                Env = Env.EnterIntoNamespace (id);
                lexer.Keywords = Env.Keywords;

                lexer.Manager.OnBeforeNamespaceParse ();

                def decls = ParseTopLevelImpl (nesting + 1);
                def namespace_tok = Token.Namespace (loc, Env, tok, decls);

                // make location of namespace body
                def endLoc = if (last_declaration_token is null)
                  Location.Default
                else
                {
                  def end = last_declaration_token.Location;
                  last_declaration_token = null;
                  end
                };

                lexer.Manager.OnAfterNamespaceParse (loc + endLoc,
                  id, idLocs, oldEnv, Env, headerLocation, br.Location, endLoc);

                Env = oldEnv;
                lexer.Keywords = Env.Keywords;

                //Message.Debug($"Writing token: $(get_token_type(namespace_tok))");
                current_stream.Add (namespace_tok);

              | x => Message.Error (x.Location, "expecting `{' opening namespace scope")
            }
            finish_current (current_begin);
            currentNsEnv = prevNsEnv;
            loop ()

          // finish entire brace group
          | Token.EndBrace when nesting > 0 =>
            last_declaration_token = tok;
            reset_comment (tok);
            finish_parent (parent_begin, current_begin);

          // finish current loose group
          | Token.Semicolon => finish_current (current_begin, tok); loop ()
          
          | Token.NewLine as nl => 
            when(terminates_statement(nl)) {
              finish_current(current_begin, tok)
            }
            loop()
          
          | Token.EndOfFile when parent_begin == 0 =>
            // check #region/#endregion completion
            match (lexer.IncompleteRegions)
            {
              | h :: _ => Message.Error (h.Location, "#endregion directive expected")
              | [] => ()
            }

            def brace_group = finish_parent (parent_begin, current_begin);
            finished = true;
            last_declaration_token = tok;
            brace_group;

          | _ => handle_default_token (current_begin, tok, true); loop ()
        }
      }
      try { loop () }
      catch { e is PreParserException =>
        Message.Error (e.Location, e.Message);
        finish_parent (parent_begin, current_begin);
      }
    }

    static parseTypeName(_idToks2 : list[Token], _brace : Token) : FixedType
    {
      null
    }

    indention_based_copy () : PreParser
    {
      def copy = PreParserIndent (lexer);
      token_buffer.Iter(copy.token_buffer.Push(_));
      copy.Env = Env;
      copy.finished = finished;
      copy
    }

    public ParseTopLevel () : Token.BracesGroup {
      try {
        def stream = ParseTopLevelImpl ();
        Token.BracesGroup (if (stream != null) stream.Location else Location.Default, stream, null, null, true)
      } catch {
        | _ is LexerBase.PragmaIndent =>
          indention_based_copy ().ParseTopLevel ()
      }
    }

    [Nemerle.Assertions.Ensures (value != null)]
    public PreParse () : Token.BracesGroup {
      try {
        def top = parse_brace_group (lexer.Location, null, false, true);
        unless (finished)
          Message.Error (lexer.Location, "expected end of file, encountered closing brace");
        top
      } catch {
        | _ is LexerBase.PragmaIndent =>
          indention_based_copy ().PreParse ()
      }
    }

    static shift_end(loc : Location) : Location
    {
      if (loc.EndColumn > 1)
        Location(loc.FileIndex, loc.Line, loc.Column, loc.EndLine, loc.EndColumn - 1);
      else
        loc
    }
  }
}

